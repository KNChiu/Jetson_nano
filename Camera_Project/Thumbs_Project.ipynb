{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' 不是內部或外部命令、可執行的程式或批次檔。\n"
     ]
    }
   ],
   "source": [
    "# Full reset of the camera\n",
    "\n",
    "!echo 'dlinano' | sudo -S systemctl restart nvargus-daemon && printf '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check device number\n",
    "\n",
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-5-5d7cffda44ff>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-5d7cffda44ff>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    from jetcam.usb_camera import USBCamera\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# USB Camera (Logitech C270 webcam)\n",
    "\n",
    "  from jetcam.usb_camera import USBCamera\n",
    "  camera = USBCamera(width=224, height=224, capture_device=0) # capture_device=0 USB port\n",
    "  \n",
    "  camera.running = True\n",
    "  print(\"camera created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-1bf4ca1a9851>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-1bf4ca1a9851>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    import torchvision.transforms as transforms\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Task\n",
    "\n",
    " ## Define TASK and CATEGORIES parameters ,in this project it's already been defined,\n",
    "  ## so just define your project TASK and what CATEGORIES of data you will collect. \n",
    "  \n",
    "  import torchvision.transforms as transforms\n",
    "  from dataset import ImageClassificationDataset\n",
    "  \n",
    "  # set task name \n",
    "  TASK = 'thumbs'\n",
    "  \n",
    "  # what categories we need\n",
    "  CATEGORIES = ['thumbs_up', 'thumbs_down']\n",
    "  \n",
    "  \n",
    "  DATASETS = ['A', 'B']\n",
    "  \n",
    "  TRANSFORMS = transforms.Compose([    # 用於把一系列變換組合到一起。\n",
    "  \n",
    "      # transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0) 修改亮度、對比度和飽和度\n",
    "      transforms.ColorJitter(0.2, 0.2, 0.2, 0.2), \n",
    "      \n",
    "      # transforms.Resize(size, interpolation=2) 重置影象解析度\n",
    "      transforms.Resize((224, 224)),\n",
    "      \n",
    "      # 轉換為 tensor\n",
    "      transforms.ToTensor(),\n",
    "      \n",
    "      # transforms.Normalize(mean, std) 進行標準化，先減均值，再除以標準差\n",
    "      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "\n",
    "  datasets = {}\n",
    "  \n",
    "  for name in DATASETS:\n",
    "      datasets[name] = ImageClassificationDataset(TASK + '_' + name, CATEGORIES, TRANSFORMS)\n",
    "\n",
    "  print(\"{} task with {} categories defined\".format(TASK, CATEGORIES))\n",
    "  \n",
    "  # https://www.itread01.com/content/1546227125.html\n",
    "  # https://www.itread01.com/content/1546227125.html#10transformsNormalize_120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-7-215e672c56da>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-215e672c56da>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    import ipywidgets\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Data Collection\n",
    "\n",
    "## Collect images for your categories with your camera using an iPython widget. \n",
    "  import ipywidgets\n",
    "  import traitlets\n",
    "  from IPython.display import display\n",
    "  from jetcam.utils import bgr8_to_jpeg\n",
    "\n",
    "  # initialize active dataset\n",
    "  dataset = datasets[DATASETS[0]]\n",
    "\n",
    "  # unobserve all callbacks from camera in case we are running this cell for second time\n",
    "  camera.unobserve_all()\n",
    "\n",
    "  # create image preview\n",
    "  camera_widget = ipywidgets.Image()\n",
    "  traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "  # create widgets\n",
    "  dataset_widget = ipywidgets.Dropdown(options=DATASETS, description='dataset')\n",
    "  category_widget = ipywidgets.Dropdown(options=dataset.categories, description='category')\n",
    "  count_widget = ipywidgets.IntText(description='count')\n",
    "  save_widget = ipywidgets.Button(description='add')\n",
    "\n",
    "  # manually update counts at initialization\n",
    "  count_widget.value = dataset.get_count(category_widget.value)\n",
    "\n",
    "  # sets the active dataset\n",
    "  def set_dataset(change):\n",
    "      global dataset\n",
    "      dataset = datasets[change['new']]\n",
    "      count_widget.value = dataset.get_count(category_widget.value)\n",
    "  dataset_widget.observe(set_dataset, names='value')\n",
    "\n",
    "  # update counts when we select a new category\n",
    "  def update_counts(change):\n",
    "      count_widget.value = dataset.get_count(change['new'])\n",
    "  category_widget.observe(update_counts, names='value')\n",
    "\n",
    "  # save image for category and update counts\n",
    "  def save(c):\n",
    "      dataset.save_entry(camera.value, category_widget.value)\n",
    "      count_widget.value = dataset.get_count(category_widget.value)\n",
    "  save_widget.on_click(save)\n",
    "\n",
    "  data_collection_widget = ipywidgets.VBox([\n",
    "      ipywidgets.HBox([camera_widget]), dataset_widget, category_widget, count_widget, save_widget\n",
    "  ])\n",
    "\n",
    "  # display(data_collection_widget)\n",
    "  print(\"data_collection_widget created\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-8-b6fe310fdf04>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-b6fe310fdf04>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    import torchvision\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "import torch\n",
    "  import torchvision\n",
    "  \n",
    "  # Choose GPU device with the statement.\n",
    "  device = torch.device('cuda')\n",
    "\n",
    "  # The model is set to the ResNet-18 model.\n",
    "  # pretrained=True parameter indicates we are loading all the parameter weights for the trained Resnet-18 model.\n",
    "  model = torchvision.models.resnet18(pretrained=True)\n",
    "  \n",
    "  #指维度\n",
    "  model.fc = torch.nn.Linear(512, len(dataset.categories))\n",
    "\n",
    "  model = model.to(device)\n",
    "\n",
    "  model_save_button = ipywidgets.Button(description='save model')\n",
    "  model_load_button = ipywidgets.Button(description='load model')\n",
    "  model_path_widget = ipywidgets.Text(description='model path', value='my_model.pth')\n",
    "\n",
    "  def load_model(c):\n",
    "      model.load_state_dict(torch.load(model_path_widget.value))\n",
    "  model_load_button.on_click(load_model)\n",
    "\n",
    "  def save_model(c):\n",
    "      torch.save(model.state_dict(), model_path_widget.value)\n",
    "  model_save_button.on_click(save_model)\n",
    "\n",
    "  model_widget = ipywidgets.VBox([\n",
    "      model_path_widget,\n",
    "      ipywidgets.HBox([model_load_button, model_save_button])\n",
    "  ])\n",
    "\n",
    "  # display(model_widget)\n",
    "  print(\"model configured and model_widget created\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-9-a778b05f60e5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-a778b05f60e5>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    import time\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Live Execution\n",
    "\n",
    "import threading  \n",
    "  import time\n",
    "  from utils import preprocess\n",
    "  import torch.nn.functional as F\n",
    "\n",
    "  state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "  prediction_widget = ipywidgets.Text(description='prediction')\n",
    "  score_widgets = []\n",
    "  for category in dataset.categories:\n",
    "      score_widget = ipywidgets.FloatSlider(min=0.0, max=1.0, description=category, orientation='vertical')\n",
    "      score_widgets.append(score_widget)\n",
    "\n",
    "  def live(state_widget, model, camera, prediction_widget, score_widget):\n",
    "      global dataset\n",
    "      while state_widget.value == 'live':\n",
    "          image = camera.value\n",
    "          preprocessed = preprocess(image)\n",
    "          output = model(preprocessed)\n",
    "          output = F.softmax(output, dim=1).detach().cpu().numpy().flatten()\n",
    "          category_index = output.argmax()\n",
    "          prediction_widget.value = dataset.categories[category_index]\n",
    "          for i, score in enumerate(list(output)):\n",
    "              score_widgets[i].value = score\n",
    "\n",
    "  def start_live(change):\n",
    "      if change['new'] == 'live':\n",
    "          execute_thread = threading.Thread(target=live, args=(state_widget, model, camera, prediction_widget, score_widget))\n",
    "          execute_thread.start()\n",
    "\n",
    "  state_widget.observe(start_live, names='value')\n",
    "\n",
    "  live_execution_widget = ipywidgets.VBox([\n",
    "      ipywidgets.HBox(score_widgets),\n",
    "      prediction_widget,\n",
    "      state_widget\n",
    "  ])\n",
    "\n",
    "  # display(live_execution_widget)\n",
    "  print(\"live_execution_widget created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-10-0cb934326be6>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-0cb934326be6>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    optimizer = torch.optim.Adam(model.parameters())\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "  optimizer = torch.optim.Adam(model.parameters())\n",
    "  # optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    "\n",
    "  epochs_widget = ipywidgets.IntText(description='epochs', value=1)\n",
    "  eval_button = ipywidgets.Button(description='evaluate')\n",
    "  train_button = ipywidgets.Button(description='train')\n",
    "  loss_widget = ipywidgets.FloatText(description='loss')\n",
    "  accuracy_widget = ipywidgets.FloatText(description='accuracy')\n",
    "  progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress')\n",
    "\n",
    "  def train_eval(is_training):\n",
    "      global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, accuracy_widget, loss_widget, progress_widget, state_widget\n",
    "\n",
    "      try:\n",
    "          train_loader = torch.utils.data.DataLoader(\n",
    "              dataset,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              shuffle=True\n",
    "          )\n",
    "\n",
    "          state_widget.value = 'stop'\n",
    "          train_button.disabled = True\n",
    "          eval_button.disabled = True\n",
    "          time.sleep(1)\n",
    "\n",
    "          if is_training:\n",
    "              model = model.train()\n",
    "          else:\n",
    "              model = model.eval()\n",
    "          while epochs_widget.value > 0:\n",
    "              i = 0\n",
    "              sum_loss = 0.0\n",
    "              error_count = 0.0\n",
    "              for images, labels in iter(train_loader):\n",
    "                  # send data to device\n",
    "                  images = images.to(device)\n",
    "                  labels = labels.to(device)\n",
    "\n",
    "                  if is_training:\n",
    "                      # zero gradients of parameters\n",
    "                      optimizer.zero_grad()\n",
    "\n",
    "                  # execute model to get outputs\n",
    "                  outputs = model(images)\n",
    "\n",
    "                  # compute loss\n",
    "                  loss = F.cross_entropy(outputs, labels)\n",
    "\n",
    "                  if is_training:\n",
    "                      # run backpropogation to accumulate gradients\n",
    "                      loss.backward()\n",
    "\n",
    "                      # step optimizer to adjust parameters\n",
    "                      optimizer.step()\n",
    "\n",
    "                  # increment progress\n",
    "                  error_count += len(torch.nonzero(outputs.argmax(1) - labels).flatten())\n",
    "                  count = len(labels.flatten())\n",
    "                  i += count\n",
    "                  sum_loss += float(loss)\n",
    "                  progress_widget.value = i / len(dataset)\n",
    "                  loss_widget.value = sum_loss / i\n",
    "                  accuracy_widget.value = 1.0 - error_count / i\n",
    "\n",
    "              if is_training:\n",
    "                  epochs_widget.value = epochs_widget.value - 1\n",
    "              else:\n",
    "                  break\n",
    "      except e:\n",
    "          pass\n",
    "      model = model.eval()\n",
    "\n",
    "      train_button.disabled = False\n",
    "      eval_button.disabled = False\n",
    "      state_widget.value = 'live'\n",
    "\n",
    "  train_button.on_click(lambda c: train_eval(is_training=True))\n",
    "  eval_button.on_click(lambda c: train_eval(is_training=False))\n",
    "\n",
    "  train_eval_widget = ipywidgets.VBox([\n",
    "      epochs_widget,\n",
    "      progress_widget,\n",
    "      loss_widget,\n",
    "      accuracy_widget,\n",
    "      ipywidgets.HBox([train_button, eval_button])\n",
    "  ])\n",
    "\n",
    "  # display(train_eval_widget)\n",
    "  print(\"trainer configured and train_eval_widget created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Interactive Tool\n",
    "\n",
    "  # Combine all the widgets into one display\n",
    "  all_widget = ipywidgets.VBox([\n",
    "      ipywidgets.HBox([data_collection_widget, live_execution_widget]), \n",
    "      train_eval_widget,\n",
    "      model_widget\n",
    "  ])\n",
    "\n",
    "  display(all_widget)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
